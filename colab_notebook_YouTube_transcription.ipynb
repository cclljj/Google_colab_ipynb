{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPo0eCfAyowtREV4H0qFWze",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cclljj/Google_colab_ipynb/blob/master/colab_notebook_YouTube_transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarization of YouTube audio content\n",
        "\n",
        "The following steps are used to generate a summary of a specified YouTube video: \n",
        "\n",
        "1. Pytube is used to extract the audio track from the video. \n",
        "2. OpenAI Whisper is employed to transcribe the audio into text. \n",
        "3. The text is summarized using the OpenAI ChatGPT API."
      ],
      "metadata": {
        "id": "JZHhMCiCJ5uI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We install several Python libraries using the pip package manager. The first two libraries, Pytube and Pydub, are used for downloading and processing audio files, respectively. The third library, OpenAI, provides access to OpenAI's GPT-3 language model, which can generate natural language text based on a given prompt. The fourth library, OpenAI-Whisper, is used to securely access the GPT-3 language model without exposing private API keys or data. Overall, these libraries provide useful tools for working with audio and natural language processing tasks in Python."
      ],
      "metadata": {
        "id": "8e-LHvUlIkTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Pytube library for downloading YouTube videos\n",
        "!pip install -q --upgrade pytube\n",
        "\n",
        "# Install the Pydub library for working with audio files\n",
        "!pip install -q --upgrade pydub\n",
        "\n",
        "# Install the OpenAI library for accessing OpenAI's GPT-3 language model\n",
        "!pip install -q --upgrade openai\n",
        "\n",
        "# Install the OpenAI-Whisper library for securely accessing OpenAI's GPT-3 language model\n",
        "!pip install -q --upgrade openai-whisper"
      ],
      "metadata": {
        "id": "hD_CjamXuVAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea4dd3a-4dfd-443c-9ecd-f00ec2540e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.9/792.9 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we set up the necessary environment for a Python program that uses these libraries and APIs.\n",
        "\n",
        "The code imports several libraries including pytube for downloading YouTube videos, pydub for working with audio files, whisper for sending and receiving messages over a network, and re for working with regular expressions.\n",
        "\n",
        "The code also sets the OPENAI_API_KEY environment variable using %env so that it can be used to authenticate API requests to OpenAI. Then, it sets the OpenAI API key and organization using the openai library."
      ],
      "metadata": {
        "id": "88YDPd42IEvU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfuqfAgLuO-n",
        "outputId": "d490eb31-6375-41ff-f863-16ced17c9551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: OPENAI_API_KEY=sk-my_openai_key\n"
          ]
        }
      ],
      "source": [
        "# Import the necessary libraries\n",
        "from pytube import YouTube    # library for downloading YouTube videos\n",
        "from pydub import AudioSegment    # library for working with audio files\n",
        "import whisper    # library for sending and receiving messages over a network\n",
        "import re    # library for working with regular expressions\n",
        "\n",
        "# Set the OpenAI API key as an environment variable\n",
        "import openai    # library for working with the OpenAI API\n",
        "%env OPENAI_API_KEY=sk-my_openai_key\n",
        "\n",
        "# Set the OpenAI organization and API key\n",
        "openai.organization = \"\"\n",
        "openai.api_key = \"sk-my_openai_key\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a dictionary in Python that contains a list of YouTube video IDs mapped to their corresponding target file names. In this case, there is only one video in the list, and its target file name is \"GPT4\", while its video ID is \"oc6RV5c1yd0\". The purpose of this code may be to keep track of video IDs and their corresponding names, allowing the programmer to easily reference the correct video ID when needed."
      ],
      "metadata": {
        "id": "I755dLiKHwn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a Python dictionary that contains a list of YouTube video IDs \n",
        "# mapped to their corresponding target file names\n",
        "youtube_list = {\n",
        "    # Here, the \"GPT4\" target file name is mapped to the \"oc6RV5c1yd0\" video ID\n",
        "    \"GPT4\": \"oc6RV5c1yd0\",\n",
        "}\n"
      ],
      "metadata": {
        "id": "d8xGxkVuufuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rephrase_text function takes in one parameter called text. This function is responsible for rephrasing and improving the readability of the input text.\n",
        "\n",
        "The function uses the OpenAI API to generate an improved version of the text. It creates a prompt string called q and passes it to the openai.ChatCompletion.create() method along with the name of the GPT-3 model to be used for generating the improved text. The messages parameter is a list of two dictionaries that specify the role of the chat message sender (system or user) and the content of the chat message.\n",
        "\n",
        "After generating the improved text, the function extracts the text from the OpenAI API response and returns it as the summary."
      ],
      "metadata": {
        "id": "Kv0bk4DvYj54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rephrase_text(text, language=\"en\"):\n",
        "    # Create a prompt string to be sent to the OpenAI API\n",
        "    if language==\"zh\":\n",
        "      q = f\"請幫我用中文改錯字、加標點符號，讓內容更通順:\\n\\n{text}\\n\\n 修正後文字:\"\n",
        "    else:\n",
        "      q = f\"Please rephrase the following text:\\n{text}\\n\\nRevision:\"\n",
        "    \n",
        "    # Call the OpenAI API to generate an improved version of the text\n",
        "    rsp = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Editor\"},\n",
        "            {\"role\": \"user\", \"content\": q}\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # Extract the improved text from the OpenAI API response\n",
        "    summary = rsp.get(\"choices\")[0][\"message\"][\"content\"].strip()\n",
        "    \n",
        "    # Return the improved text\n",
        "    return summary"
      ],
      "metadata": {
        "id": "8k3gMypfNe9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The split_article function takes in an article string and a maximum number of words max_words as inputs. It splits the article into pieces where each piece has a maximum word count of max_words.\n",
        "\n",
        "To do this, it first initializes a word_count variable to 0, a pieces list to store the article pieces, and a current_piece string to store the current article piece being processed.\n",
        "\n",
        "Next, the function uses the re module's split() method to split the article string into lines at each period and space (.\\s). The resulting lines list contains each sentence as a separate element.\n",
        "\n",
        "For each line in the lines list, the function appends a period and space to the end of the line to ensure that the split sentence remains grammatically correct. The line is then split into words using the split() method, and the length of the resulting words list is stored in words_length.\n",
        "\n",
        "If the sum of the word_count and words_length is greater than the max_words, the current_piece is sent to a separate function rephrase_text for any necessary modification, appended to the pieces list, and reset to the current line. The word_count is also reset to the length of the current line's words list.\n",
        "\n",
        "If the sum of the word_count and words_length is less than or equal to the max_words, the current line is added to the current_piece string, and the word_count is incremented by the length of the current line's words list.\n",
        "\n",
        "Finally, the last current_piece is appended to the pieces list and the list is returned."
      ],
      "metadata": {
        "id": "pdVkrzQkGwuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_article(article, language=\"en\", max_words=1000):\n",
        "    word_count = 0   # word count of the current piece\n",
        "    pieces = []      # list to store article pieces\n",
        "    current_piece = \"\"  \n",
        "    \n",
        "    if language==\"zh\":\n",
        "        max_words = 500\n",
        "        lines = re.split(r\"，\", article)  # split article into lines at each period and space\n",
        "    else:\n",
        "        lines = re.split(r\"\\.\\s\", article)  # split article into lines at each period and space\n",
        "    \n",
        "    for line in lines:\n",
        "        if language==\"zh\":\n",
        "            line = line + \"，\"  # add period and space to end of line for grammatical correctness\n",
        "            words_length = len(line)  # get length of words\n",
        "        else:\n",
        "            line = line + \". \"  # add period and space to end of line for grammatical correctness\n",
        "            words = line.split()  # split line into words\n",
        "            words_length = len(words)  # get length of words list\n",
        "        \n",
        "        if ((word_count + words_length) > max_words):  # if word count exceeds max_words\n",
        "            current_piece = rephrase_text(current_piece, language)  # send current piece to rephrase_text function for modification\n",
        "            pieces.append(current_piece)  # append modified piece to pieces list\n",
        "            current_piece = line  # reset current piece to current line\n",
        "            word_count = words_length  # reset word count to length of current line's words list\n",
        "        else:\n",
        "            current_piece += line  # add current line to current piece\n",
        "            word_count += words_length  # increment word count by length of current line's words list\n",
        "        \n",
        "    pieces.append(current_piece)  # append last current piece to pieces list\n",
        "    return pieces  # return list of article pieces"
      ],
      "metadata": {
        "id": "BSXHTfvl18Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The summarize_text() function takes in a piece of text as input and returns a summarized version of it generated by OpenAI's GPT-3.5 Turbo model. The function does this by first creating a question to ask the AI model to summarize the given text. This question is in the form of a string that includes the text and a Summary label.\n",
        "\n",
        "Then, the function uses OpenAI's ChatCompletion API to generate a summary of the text. It passes the question and a few other parameters to the ChatCompletion.create() method, which makes a request to the GPT-3.5 Turbo model to generate the summary.\n",
        "\n",
        "The AI model's response includes the generated summary, which the function extracts and returns as output."
      ],
      "metadata": {
        "id": "GWTw9vXYI6LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(text, language=\"en\"):\n",
        "    # Create a question for the AI model to summarize the text\n",
        "    if language==\"zh\":\n",
        "        q = f\"請依據下列的文字進行摘要:\\n{text}\\n\\n摘要:\"\n",
        "    else:\n",
        "        q = f\"Please summarize the following text:\\n{text}\\n\\nSummary:\"\n",
        "\n",
        "    # Use OpenAI's GPT-3.5 Turbo model to generate a summary of the text\n",
        "    rsp = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Editor\"},\n",
        "            {\"role\": \"user\", \"content\": q}\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # Get the summary from the AI model's response\n",
        "    summary = rsp.get(\"choices\")[0][\"message\"][\"content\"].strip()\n",
        "    \n",
        "    # Return the summary\n",
        "    return summary"
      ],
      "metadata": {
        "id": "I9ZwCxmE1oXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This following code downloads a video from YouTube, extracts the audio, transcribes the audio to text using a pre-trained speech recognition model, summarizes the resulting text, and saves the summarized text to a text file.\n",
        "\n",
        "The code starts by iterating over a dictionary called \"youtube_list\" that contains the titles and unique IDs of the YouTube videos to be downloaded. For each video in the list, it prints a message indicating that the video is being downloaded, creates a YouTube object using the video's unique ID, and downloads the audio stream for that video to a temporary directory.\n",
        "\n",
        "After downloading the audio file, the code loads it into an AudioSegment object and prints information about the audio file, such as its length and format. It then converts the audio file to an MP3 format and saves it to the temporary directory.\n",
        "\n",
        "The code then loads a pre-trained speech recognition model called \"small\" and transcribes the audio file to text using that model. The resulting text is stored in a variable called \"msg\", and the language of the transcribed text is stored in a variable called \"lang\".\n",
        "\n",
        "The code then splits the transcribed text into smaller messages using the \"split_article\" function and enters a while loop that runs as long as the length of the resulting \"msgs\" list is greater than 1. Within the while loop, the code initializes an empty string called \"summary\" and iterates over each message in the \"msgs\" list. For each message, it calls the \"summarize_text\" function to summarize the text and appends the result to the \"summary\" variable.\n",
        "\n",
        "Once all messages in the \"msgs\" list have been summarized, the code splits the resulting \"summary\" string into smaller messages and assigns the resulting list back to the \"msgs\" variable. The while loop then repeats until the length of the \"msgs\" list is reduced to 1.\n",
        "\n",
        "Finally, the code creates a new text file with the same name as the original video file and saves the first message in the \"msgs\" list to that file. The code prints a message indicating the name of the output file and then closes the file."
      ],
      "metadata": {
        "id": "TayuiUREHjDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate over the items in the youtube_list dictionary\n",
        "for k, v in youtube_list.items():\n",
        "\n",
        "    # print statement to indicate which video is being downloaded\n",
        "    print(\"Downloading \" + k + \" (\" + v + \")\")\n",
        "\n",
        "    # create a YouTube object for the video using its unique ID\n",
        "    yt = YouTube(\"https://www.youtube.com/watch?v=\" + v)\n",
        "\n",
        "    # filter for the audio stream and download it to a temp directory\n",
        "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
        "    audio_stream.download(output_path=\"/tmp/\", filename=\"audio_\" + k)\n",
        "\n",
        "    # load the audio file into an AudioSegment object\n",
        "    audio_file = AudioSegment.from_file(\"/tmp/audio_\" + k)\n",
        "\n",
        "    # convert the audio file to an MP3 format and save it to the temp directory\n",
        "    mp3_file = audio_file.export(\"/tmp/audio_\" + k + \".mp3\", format=\"mp3\")\n",
        "\n",
        "    # load the small model for speech recognition and transcribe the audio file\n",
        "    model = whisper.load_model(\"small\")\n",
        "    result = model.transcribe(\"/tmp/audio_\" + k + \".mp3\")\n",
        "\n",
        "    # store the transcribed text in a variable\n",
        "    msg = result[\"text\"]\n",
        "    lang = result[\"language\"]\n",
        "\n",
        "    if lang==\"zh\":\n",
        "      msg = \"\"\n",
        "      txt_writer = get_writer(\"txt\", \".\")\n",
        "      txt_writer(result, k + \"2.txt\")\n",
        "      with open(k + \"2.txt\") as f:\n",
        "        lines = f.read().splitlines() \n",
        "      for line in lines:\n",
        "        msg += line + \"，\"\n",
        "    # split the article or text message into smaller messages\n",
        "    msgs = split_article(msg, lang)\n",
        "\n",
        "    # while loop that runs as long as the length of the msgs list is greater than 1\n",
        "    while len(msgs)>1:\n",
        "\n",
        "      # initialize a variable to an empty string\n",
        "      summary = \"\"\n",
        "\n",
        "      # iterate over each message in the msgs list\n",
        "      for m in msgs:\n",
        "\n",
        "        # call the summarize_text function and append the result to the summary variable\n",
        "        r = summarize_text(m, lang)\n",
        "        summary += r\n",
        "\n",
        "      # split the summary variable into smaller messages and assign the resulting list to msgs\n",
        "      msgs = split_article(summary, lang)\n",
        "\n",
        "    # write the transcribed text to a file with the name of the YouTube video\n",
        "    with open(k + \".txt\", \"w\") as out_file:\n",
        "      print(\"Output file: \" + k + \".txt\")\n",
        "      out_file.write(msgs[0])\n",
        "      out_file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnxb2243ug6w",
        "outputId": "2f09b0db-b433-489d-9540-437b749aabc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading macgpt (EYhlGV9AZHI)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output file: macgpt.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference\n",
        "\n",
        "- [林鼎淵 - 在 Local 導入 Whisper 套件，用 Python 免費將 Youtube 影片轉換成逐字稿！\n",
        "](https://medium.com/dean-lin/%E5%9C%A8-local-%E5%B0%8E%E5%85%A5-whisper-%E5%A5%97%E4%BB%B6-%E5%85%8D%E8%B2%BB%E5%B0%87-youtube-%E5%BD%B1%E7%89%87%E8%BD%89%E6%8F%9B%E6%88%90%E9%80%90%E5%AD%97%E7%A8%BF-3227c5c68074)"
      ],
      "metadata": {
        "id": "OwVtd-PYVm0s"
      }
    }
  ]
}