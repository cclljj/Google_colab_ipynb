{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEkbM6aXBxVQEaZUeonGlD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cclljj/Google_colab_ipynb/blob/master/colab_notebook_YouTube_transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarization of YouTube audio content\n",
        "\n",
        "The following steps are used to generate a summary of a specified YouTube video: \n",
        "\n",
        "1. Pytube is used to extract the audio track from the video. \n",
        "2. OpenAI Whisper is employed to transcribe the audio into text. \n",
        "3. The text is summarized using the OpenAI ChatGPT API."
      ],
      "metadata": {
        "id": "JZHhMCiCJ5uI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We install several Python libraries using the pip package manager. The first two libraries, Pytube and Pydub, are used for downloading and processing audio files, respectively. The third library, OpenAI, provides access to OpenAI's GPT-3 language model, which can generate natural language text based on a given prompt. The fourth library, OpenAI-Whisper, is used to securely access the GPT-3 language model without exposing private API keys or data. Overall, these libraries provide useful tools for working with audio and natural language processing tasks in Python."
      ],
      "metadata": {
        "id": "8e-LHvUlIkTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Pytube library for downloading YouTube videos\n",
        "!pip install -q --upgrade pytube\n",
        "\n",
        "# Install the Pydub library for working with audio files\n",
        "!pip install -q --upgrade pydub\n",
        "\n",
        "# Install the OpenAI library for accessing OpenAI's GPT-3 language model\n",
        "!pip install -q --upgrade openai\n",
        "\n",
        "# Install the OpenAI-Whisper library for securely accessing OpenAI's GPT-3 language model\n",
        "!pip install -q --upgrade openai-whisper"
      ],
      "metadata": {
        "id": "hD_CjamXuVAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782a9cf1-155e-4c56-b4d9-36c4920cf328"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.9/792.9 KB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we set up the necessary environment for a Python program that uses these libraries and APIs.\n",
        "\n",
        "The code imports several libraries including pytube for downloading YouTube videos, pydub for working with audio files, whisper for sending and receiving messages over a network, and re for working with regular expressions.\n",
        "\n",
        "The code also sets the OPENAI_API_KEY environment variable using %env so that it can be used to authenticate API requests to OpenAI. Then, it sets the OpenAI API key and organization using the openai library."
      ],
      "metadata": {
        "id": "88YDPd42IEvU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfuqfAgLuO-n",
        "outputId": "28bf00fc-7a80-4b71-860b-bdbf82e56cb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: OPENAI_API_KEY=sk-your_key\n"
          ]
        }
      ],
      "source": [
        "# Import the necessary libraries\n",
        "from pytube import YouTube    # library for downloading YouTube videos\n",
        "from pydub import AudioSegment    # library for working with audio files\n",
        "import whisper    # library for sending and receiving messages over a network\n",
        "import re    # library for working with regular expressions\n",
        "\n",
        "# Set the OpenAI API key as an environment variable\n",
        "import openai    # library for working with the OpenAI API\n",
        "%env OPENAI_API_KEY=sk-your_key\n",
        "\n",
        "# Set the OpenAI organization and API key\n",
        "openai.organization = \"\"\n",
        "openai.api_key = \"sk-your_key\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a dictionary in Python that contains a list of YouTube video IDs mapped to their corresponding target file names. In this case, there is only one video in the list, and its target file name is \"GPT4\", while its video ID is \"oc6RV5c1yd0\". The purpose of this code may be to keep track of video IDs and their corresponding names, allowing the programmer to easily reference the correct video ID when needed."
      ],
      "metadata": {
        "id": "I755dLiKHwn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a Python dictionary that contains a list of YouTube video IDs \n",
        "# mapped to their corresponding target file names\n",
        "youtube_list = {\n",
        "    # Here, the \"GPT4\" target file name is mapped to the \"oc6RV5c1yd0\" video ID\n",
        "    \"GPT4\": \"oc6RV5c1yd0\",\n",
        "}\n"
      ],
      "metadata": {
        "id": "d8xGxkVuufuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python code downloads audio files for a list of YouTube videos and transcribes them using a pre-trained speech recognition model. It first iterates through the youtube_list items, printing a message to indicate which video is being downloaded. It then creates a YouTube object for the video using its unique ID and filters for the audio stream, downloading it to a temporary directory. The audio file is then loaded into an AudioSegment object and printed for information.\n",
        "\n",
        "Next, the audio file is converted to an MP3 format and saved to the temporary directory. The code then loads a pre-trained base model for speech recognition using the whisper.load_model() function and transcribes the audio file using the model.transcribe() method. The transcribed text is stored in the msg variable for further use."
      ],
      "metadata": {
        "id": "TayuiUREHjDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through the youtube_list items\n",
        "for k, v in youtube_list.items():\n",
        "    # print statement to indicate which video is being downloaded\n",
        "    print(\"Downloading \" + k + \" (\" + v + \")\")\n",
        "    # create a YouTube object for the video using its unique ID\n",
        "    yt = YouTube(\"https://www.youtube.com/watch?v=\" + v)\n",
        "\n",
        "    # filter for the audio stream and download it to a temp directory\n",
        "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
        "    audio_stream.download(output_path=\"/tmp/\", filename=\"audio_\" + k)\n",
        "\n",
        "    # load the audio file into an AudioSegment object\n",
        "    audio_file = AudioSegment.from_file(\"/tmp/audio_\" + k)\n",
        "\n",
        "    # print information about the audio file\n",
        "    print(audio_file)\n",
        "\n",
        "    # convert the audio file to an MP3 format and save it to the temp directory\n",
        "    mp3_file = audio_file.export(\"/tmp/audio_\" + k + \".mp3\", format=\"mp3\")\n",
        "\n",
        "    # load the base model for speech recognition and transcribe the audio file\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(\"/tmp/audio_\" + k + \".mp3\")\n",
        "\n",
        "    # store the transcribed text in a variable\n",
        "    msg = result[\"text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnxb2243ug6w",
        "outputId": "f905b326-165a-4408-cb71-786870c4b999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading GPT4 (oc6RV5c1yd0)\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9af054e280>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function takes an article (a string) and splits it into smaller pieces (also strings) based on a maximum word count. The function splits the article into sentences using a regular expression, then loops through each sentence, keeping track of the word count in the current piece. If adding a sentence to the current piece would exceed the maximum word count, the current piece is added to the list of article pieces, and a new piece is started with the current sentence. If the word count of the current piece is below the maximum, the current sentence is added to the current piece. Finally, the last piece is added to the list of article pieces, and the list is returned."
      ],
      "metadata": {
        "id": "pdVkrzQkGwuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_article(article, max_words=3000):\n",
        "    # Initialize variables\n",
        "    word_count = 0   # word count of the current piece\n",
        "    pieces = []      # list to store article pieces\n",
        "    current_piece = \"\"  # current piece of the article being processed\n",
        "    \n",
        "    # Split the article into sentences using regular expression\n",
        "    lines = re.split(r\"\\.\\s\", article)\n",
        "    \n",
        "    # Loop through each sentence\n",
        "    for line in lines:\n",
        "        line = line + \". \"   # add period to the end of each sentence\n",
        "        words = line.split() # split the sentence into words\n",
        "        words_length = len(words) # get the number of words in the sentence\n",
        "        \n",
        "        # Check if adding the sentence to the current piece exceeds the maximum word count\n",
        "        if ((word_count + words_length) > max_words):\n",
        "            pieces.append(current_piece) # add the current piece to the list of article pieces\n",
        "            current_piece = line    # start a new piece with the current sentence\n",
        "            word_count = words_length   # set the word count to the number of words in the sentence\n",
        "        else:\n",
        "            current_piece += line   # add the current sentence to the current piece\n",
        "            word_count += words_length  # add the number of words in the sentence to the word count\n",
        "        \n",
        "    pieces.append(current_piece)   # add the last piece to the list of article pieces\n",
        "    return pieces   # return the list of article pieces"
      ],
      "metadata": {
        "id": "BSXHTfvl18Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python function uses OpenAI's GPT-3.5 Turbo model to summarize a given text. It first creates a question string q to ask the AI model to summarize the text. It then uses the openai.ChatCompletion.create() method to send a message to the AI model with the question string as user input. The AI model generates a response that includes the summarized text. The function extracts the summarized text from the AI model's response and returns it.\n",
        "\n",
        "This function can be useful for automatically summarizing large amounts of text, such as news articles or research papers. However, it's important to note that the quality of the summary will depend on the capabilities of the AI model used and the complexity of the text being summarized."
      ],
      "metadata": {
        "id": "GWTw9vXYI6LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(text):\n",
        "    # Create a question for the AI model to summarize the text\n",
        "    q = f\"Please summarize the following text:\\n{text}\\n\\nSummary:\"\n",
        "    #q = f\"請依據下列的文字進行摘要:\\n{text}\\n\\n摘要:\"\n",
        "\n",
        "    # Use OpenAI's GPT-3.5 Turbo model to generate a summary of the text\n",
        "    rsp = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Editor\"},\n",
        "            {\"role\": \"user\", \"content\": q}\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # Get the summary from the AI model's response\n",
        "    summary = rsp.get(\"choices\")[0][\"message\"][\"content\"].strip()\n",
        "    \n",
        "    # Return the summary\n",
        "    return summary"
      ],
      "metadata": {
        "id": "I9ZwCxmE1oXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code takes in an article or a text message called msg, and then splits it into smaller messages using the split_article function. It then enters a while loop that runs as long as the length of the msgs list is greater than 1.\n",
        "\n",
        "Within the loop, it initializes a variable called summary to an empty string. It then iterates over each message in the msgs list using a for loop. For each message, it calls the summarize_text function, which returns a summarized version of the message. It then appends the summarized version to the summary variable.\n",
        "\n",
        "Once it has processed all the messages in the msgs list, it splits the summary variable into smaller messages using the split_article function and assigns the resulting list back to the msgs variable. This process is repeated until there is only one message left in the msgs list.\n",
        "\n",
        "Finally, the code prints out the first message in the msgs list using print(msgs[0])."
      ],
      "metadata": {
        "id": "7qy4d3rBJXDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the article or text message into smaller messages\n",
        "msgs = split_article(msg)\n",
        "\n",
        "# while loop that runs as long as the length of the msgs list is greater than 1\n",
        "while len(msgs)>1:\n",
        "\n",
        "  # initialize a variable to an empty string\n",
        "  summary = \"\"\n",
        "\n",
        "  # iterate over each message in the msgs list\n",
        "  for m in msgs:\n",
        "\n",
        "    # call the summarize_text function and append the result to the summary variable\n",
        "    r = summarize_text(m)\n",
        "    summary += r\n",
        "\n",
        "  # split the summary variable into smaller messages and assign the resulting list to msgs\n",
        "  msgs = split_article(summary)\n",
        "\n",
        "# print out the first message in the msgs list\n",
        "print(msgs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYfSMbqLvOmY",
        "outputId": "306713e1-5a87-404c-8e32-001e4c1d6c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " GPT-4 is the latest AI system from OpenAI, the lab that created Dolly, and chat GPT. GPT-4 is a breakthrough in problem solving capabilities. For example, you can ask it how you would clean the inside of a tank filled with piranhas, and it'll give you something useful. It can also read, analyze, or generate up to 25,000 words of text. It can write code in all major programming languages, and it understands images as input, and can reason with them in sophisticated ways. Most importantly, after we created GPT-4, we spent months making it safer and more aligned with how you want to use it. The methods we've developed to continuously improve GPT-4 will help us as we work towards AI systems that will empower us all.. \n"
          ]
        }
      ]
    }
  ]
}